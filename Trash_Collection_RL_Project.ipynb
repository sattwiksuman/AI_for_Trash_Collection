{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trash_Collection_RL_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sattwiksuman/AI_for_Trash_Collection/blob/main/Trash_Collection_RL_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV8MUqYr-tHQ"
      },
      "source": [
        "#<center>Efficient Trash Collection using AI</center>\r\n",
        "---\r\n",
        "####<center>Reinforced Learning Project - Economic Modelling of Energy and Climate Systems</center>\r\n",
        "####<center>Data Analytics and Decision Science</center>\r\n",
        "####<center>RWTH Aachen Business School</center>\r\n",
        "Submitted by:<br>\r\n",
        "Priyanka Kundagol<br>\r\n",
        "Sattwik Suman Das<br>\r\n",
        "Ved Nerlikar\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3urOwETcGek"
      },
      "source": [
        "---\r\n",
        "#Introduction\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "To be added."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPGv-8QnZ3Wg"
      },
      "source": [
        "###The Environment\r\n",
        "The Diagram below shows the environment in which the Agent would operate.\r\n",
        "The squares in gray are the road.\r\n",
        "The Agent is expected to collect trash from the location shown in Black boxes.\r\n",
        "The trash is actually collected from the adjacent squares marked by a dark border on the road, i.e., squares 3, 17 and 21."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDkpXo769ZQL"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCZ8Ya4s_83u"
      },
      "source": [
        "###States of the Environment:\r\n",
        "The gray squares above depict the states in which the agent can reside. <br>\r\n",
        "So there are 26 states in total numbered 0 to 25. <br>\r\n",
        "The movement of the agent from one state to another is defined by defining the rewards of the adjacent states.\r\n",
        "\r\n",
        "###Actions\r\n",
        "At each state the agent can 5 actions as follows:\r\n",
        "0. Do nothing\r\n",
        "1. Move North\r\n",
        "2. Move East\r\n",
        "3. Move South\r\n",
        "4. Move West \r\n",
        "\r\n",
        "###Action_Space: control the motion\r\n",
        "For each state, the next state corresponding to the consequence of the 5 actions will be pre-defined as part of the environment definition. \r\n",
        "\r\n",
        "###Rewards\r\n",
        "The reward of the trash locations 03, 17 and 21 are defined to reflect the amount of trash in the following manner:\r\n",
        "1. if trash >= threshold:\r\n",
        "        reward= percentage of trash bin full\r\n",
        "2. else:\r\n",
        "        reward = 0\r\n",
        "<br>\r\n",
        "The threshold can be set to 70% .\r\n",
        "\r\n",
        "###Reward for road states in form of Living Penalty\r\n",
        "A Living Penalty is defined to each of the states on the road because we want the agent to move by taking the shortest time, which would ultimately be the most efficient way to travel. <br>\r\n",
        "Living Penalty is not defined to the start location '0' and the trash locations. <br>\r\n",
        "The agent is expected to reside at the starting point till it needs to make it's first trip and then reside at the location from which it has collected the trash till it needs to move to the next location to collect from the next location.<br>\r\n",
        "Living penalty can be set to -0.2\r\n",
        "\r\n",
        "###Carrying capacity of the Agent\r\n",
        "For the initial model, the agent is assumed to have infinite capacity. <br>\r\n",
        "This effectively means it never has to return to the depot to empty itself.\r\n",
        "\r\n",
        "###Timestep of the simulation\r\n",
        "The timestep can be assumed to be one hour.<br>\r\n",
        "In each timestep:\r\n",
        "1. the vehicle is assumed to have one state transition.\r\n",
        "2. the garbage is updated to new quatities\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsEbpRcKmvB8"
      },
      "source": [
        "---\r\n",
        "#Importing the packages\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THtm1DnRBmP8"
      },
      "source": [
        "import gym\r\n",
        "from gym import spaces\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from numpy.random import default_rng\r\n",
        "from random import random\r\n",
        "from random import randint\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from matplotlib import style\r\n",
        "style.use('ggplot')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVSBazS5m3Ej"
      },
      "source": [
        "---\r\n",
        "#Building the Environment\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MRG3cBD3WPT"
      },
      "source": [
        "#Build the environment\r\n",
        "\r\n",
        "class TrashEnv(gym.Env):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(TrashEnv, self).__init__()\r\n",
        "        # Define action and observation space\r\n",
        "        # They must be gym.spaces objects\r\n",
        "        n_actions = 5\r\n",
        "        #self.action_space = spaces.Discrete(n_actions)\r\n",
        "\r\n",
        "        self.total_states = 26 \r\n",
        "        self.observation_space = spaces.Discrete(self.total_states)\r\n",
        "\r\n",
        "        #Define the action space:\r\n",
        "        self.action_space = []\r\n",
        "        for _ in range(26):\r\n",
        "            self.action_space.append([])\r\n",
        "        self.action_space[0]=[0, 7, 1, 0, 0]\r\n",
        "        self.action_space[1]=[1, 1, 2, 1, 0]\r\n",
        "        self.action_space[2]=[2, 2, 3, 2, 1]\r\n",
        "        self.action_space[3]=[3, 3, 4, 3, 2]\r\n",
        "        self.action_space[4]=[4, 4, 5, 4, 3]\r\n",
        "        self.action_space[5]=[5, 6, 5, 5, 4]\r\n",
        "        self.action_space[6]=[6, 9, 6, 5, 6]\r\n",
        "        self.action_space[7]=[7, 8, 7, 0, 7]\r\n",
        "        self.action_space[8]=[8, 15, 8, 7, 8]\r\n",
        "        self.action_space[9]=[9, 10, 9, 6, 9]\r\n",
        "        self.action_space[10]=[10, 17, 10, 9, 11]\r\n",
        "        self.action_space[11]=[11, 11, 10, 11, 12]\r\n",
        "        self.action_space[12]=[12, 12, 11, 12, 13]\r\n",
        "        self.action_space[13]=[13, 13, 11, 13, 14]\r\n",
        "        self.action_space[14]=[14, 14, 13, 14, 15]\r\n",
        "        self.action_space[15]=[15, 16, 14, 8, 15]\r\n",
        "        self.action_space[16]=[16, 19, 16, 15, 16]\r\n",
        "        self.action_space[17]=[17, 18, 17, 10, 17]\r\n",
        "        self.action_space[18]=[18, 25, 18, 17, 18]\r\n",
        "        self.action_space[19]=[19, 20, 19, 16, 19]\r\n",
        "        self.action_space[20]=[20, 20, 21, 19, 20]\r\n",
        "        self.action_space[21]=[21, 21, 22, 21, 20]\r\n",
        "        self.action_space[22]=[22, 22, 23, 22, 21]\r\n",
        "        self.action_space[23]=[23, 23, 24, 23, 22]\r\n",
        "        self.action_space[24]=[24, 24, 25, 24, 23]\r\n",
        "        self.action_space[25]=[25, 25, 25, 18, 24]\r\n",
        "        \r\n",
        "        #Define the Garbage locations and corresponding initial garbage quantity values = 0:\r\n",
        "        self.garbage_quantity = {}\r\n",
        "        self.garbage_quantity[3]=0.0\r\n",
        "        self.garbage_quantity[17]=0.0\r\n",
        "        self.garbage_quantity[21]=0.0    \r\n",
        "\r\n",
        "        #Define maximum quatity of garbage that would be updated in one timestep:\r\n",
        "        self.max_garbage_update = 0.04   \r\n",
        "        \r\n",
        "        # Set the living penalty\r\n",
        "        self.living_penalty = -0.2\r\n",
        "\r\n",
        "        #Define the Rewards:\r\n",
        "        self.reward_space = []\r\n",
        "        for i in range(26):\r\n",
        "            self.reward_space.append(self.living_penalty) \r\n",
        "            if i in [3, 17, 21]:\r\n",
        "                self.reward_space[i]=self.garbage_quantity[i]\r\n",
        "        self.reward_space[0]=0.0        #reward for initial location must be zero as we allow the agent to reside at 0 before it has to start\r\n",
        "\r\n",
        "        # Create state attribute, initialize it in reset method\r\n",
        "        self.state = None\r\n",
        "\r\n",
        "        #Create a variable to measure the distance covered\r\n",
        "        self.distance_covered = 0\r\n",
        "\r\n",
        "        #Create a variable to store the number of timesteps \r\n",
        "        \r\n",
        "        \r\n",
        "    def step(self, action):\r\n",
        "        \"\"\"State transition of the model.\r\n",
        "\r\n",
        "        Implements the model of the environment.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            action (int): Action the agent took.\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            next_state (int): The next state the environment emits.\r\n",
        "            reward (float): The reward the environment emits.\r\n",
        "            done (bool): True if current state is terminal.\r\n",
        "            info (dict): Infos that can be used for debugging.\r\n",
        "        \"\"\"\r\n",
        "        #assert self.action_space.contains(action), \"%r (%s) invalid\" % (action, type(action))\r\n",
        "        #assert action <= self.state, \"%r is to much extraction, current state: %r\" % (action, self.state)\r\n",
        "\r\n",
        "        # Calculate the next state\r\n",
        "        next_state = self.action_space[self.state][action]\r\n",
        "\r\n",
        "        # Calculate the reward\r\n",
        "        reward = self.reward_space[next_state]\r\n",
        "\r\n",
        "        #Update the garbage_quantity and reward_space:\r\n",
        "        if next_state not in [3, 17, 21]:\r\n",
        "            self.garbage_quantity[3]+=random()*self.max_garbage_update\r\n",
        "            self.reward_space[3]=self.garbage_quantity[3]\r\n",
        "            self.garbage_quantity[17]+=random()*self.max_garbage_update\r\n",
        "            self.reward_space[17]=self.garbage_quantity[17]\r\n",
        "            self.garbage_quantity[21]+=random()*self.max_garbage_update\r\n",
        "            self.reward_space[21]=self.garbage_quantity[21]\r\n",
        "        else:\r\n",
        "            if self.state not in [3, 7, 21]:\r\n",
        "                if next_state == 3:\r\n",
        "                    self.garbage_quantity[3]=0.0\r\n",
        "                    self.reward_space[3]=self.garbage_quantity[3]\r\n",
        "                    self.garbage_quantity[17]+=random()*self.max_garbage_update\r\n",
        "                    self.reward_space[17]=self.garbage_quantity[17]\r\n",
        "                    self.garbage_quantity[21]+=random()*self.max_garbage_update\r\n",
        "                    self.reward_space[21]=self.garbage_quantity[21]\r\n",
        "                if next_state == 17:\r\n",
        "                    self.garbage_quantity[17]=0.0\r\n",
        "                    self.reward_space[17]=self.garbage_quantity[17]\r\n",
        "                    self.garbage_quantity[3]+=random()*self.max_garbage_update\r\n",
        "                    self.reward_space[3]=self.garbage_quantity[3]\r\n",
        "                    self.garbage_quantity[21]+=random()*self.max_garbage_update\r\n",
        "                    self.reward_space[21]=self.garbage_quantity[21]\r\n",
        "                if next_state == 21:\r\n",
        "                    self.garbage_quantity[21]=0.0\r\n",
        "                    self.reward_space[21]=self.garbage_quantity[21]\r\n",
        "                    self.garbage_quantity[3]+=random()*self.max_garbage_update\r\n",
        "                    self.reward_space[3]=self.garbage_quantity[3]\r\n",
        "                    self.garbage_quantity[17]+=random()*self.max_garbage_update\r\n",
        "                    self.reward_space[17]=self.garbage_quantity[17]\r\n",
        "            else:\r\n",
        "                self.garbage_quantity[3]+=random()*self.max_garbage_update\r\n",
        "                self.reward_space[3]=self.garbage_quantity[3]\r\n",
        "                self.garbage_quantity[17]+=random()*self.max_garbage_update\r\n",
        "                self.reward_space[17]=self.garbage_quantity[17]\r\n",
        "                self.garbage_quantity[21]+=random()*self.max_garbage_update\r\n",
        "                self.reward_space[21]=self.garbage_quantity[21]\r\n",
        "\r\n",
        "        #Update the state to the next state:\r\n",
        "        self.state = next_state        \r\n",
        "\r\n",
        "        #The episode will be continuous, so there will be no 'Game Over'/ 'Done'\r\n",
        "        done = 0\r\n",
        "\r\n",
        "        info = {}\r\n",
        "\r\n",
        "        return self.state, reward, done, info\r\n",
        "\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        \"\"\"Resets the environment.\r\n",
        "\r\n",
        "        Initializes the state.\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            state (int): Initial state\r\n",
        "\r\n",
        "        \"\"\"\r\n",
        "        self.state = 0\r\n",
        "                      \r\n",
        "        return self.state\r\n",
        "        \r\n",
        "\r\n",
        "    # We will not implement render and close function\r\n",
        "    def render(self, mode='human'):\r\n",
        "        pass\r\n",
        "    def close (self):\r\n",
        "        pass"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8jk3YmRmaiE"
      },
      "source": [
        "---\r\n",
        "#Testing the environment\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oArN8erumbM_"
      },
      "source": [
        "# Create the environment\r\n",
        "env = TrashEnv()\r\n",
        "\r\n",
        "# Reset the environment to get initial state\r\n",
        "state = env.reset()\r\n",
        "\r\n",
        "# Create a list to store all states during the simulation\r\n",
        "state_path = [state]\r\n",
        "\r\n",
        "# Loop over each time step in the episode\r\n",
        "# Use a policy to deforest 10 units each period unless there a less units left\r\n",
        "# then deforest everything\r\n",
        "done = False\r\n",
        "for _ in range(500):\r\n",
        "    action = randint(0,4)\r\n",
        "    state, reward, _, _ = env.step(action)\r\n",
        "    \r\n",
        "    state_path.append(state)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtBqeFbqXuPu"
      },
      "source": [
        "---\r\n",
        "#Building the Brain\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0BmFU-d3h0S"
      },
      "source": [
        "#Build the Brain\r\n",
        "'''\r\n",
        "BRAIN PARAMETERS (TBD):\r\n",
        "\r\n",
        "Input Layer: Should we just have the current state as the input or the current state\r\n",
        "            along with the garbage levels / rewards of the garbage locations as the input\r\n",
        "Output layer: output layer will have 5 nodes corresponding to the Q values\r\n",
        "            of the 5 possible actions possible for each state\r\n",
        "Dense layers: 2 dense layers with 10 nodes each #suggestion\r\n",
        "Compiler:\r\n",
        "    loss:'mse'\r\n",
        "    optimizer: 'Adam'\r\n",
        "    learning_rate= 0.001\r\n",
        "    #suggestions\r\n",
        "'''"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8nbqVX1X6AR"
      },
      "source": [
        "---\r\n",
        "#Creating a DQN Object (Agent)\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxUcq-GG3jeb"
      },
      "source": [
        "#Build the DQN object = Agent\r\n",
        "'''\r\n",
        "PARAMETERS:\r\n",
        "\r\n",
        "memory: list of length memory_len (we can model this as a queue)\r\n",
        "memory_max_len: length of the memory = 50 (approximately 2 days worth of timesteps)\r\n",
        "discount: 0.9\r\n",
        "\r\n",
        "METHODS:\r\n",
        "\r\n",
        "update_memory:\r\n",
        "    get the transition made in the current timestep and append it to memory\r\n",
        "    #transition is defined by [current_state, action, next_state, reward]\r\n",
        "    if len of memory is == memory_max_len: pop(first element)\r\n",
        "\r\n",
        "get_batch:\r\n",
        "    batch_size: 10\r\n",
        "    input_batch = randomly select min(batch_size, len(memory)) number of states\r\n",
        "                from the memory\r\n",
        "    target_batch = for each of the states in the input_batch, \r\n",
        "                corresponding element of the target_batch will be a list containing\r\n",
        "                the Q values for all the possible actions for that state\r\n",
        "                predicted by the Brain; here we will subsequently have to update\r\n",
        "                the Q_value corresponding to the action played (from the memory)\r\n",
        "                to reward + discount * max(predicted values for next_state)\r\n",
        "\r\n",
        "'''"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSKHFWvvYKhz"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "#Training\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZVxmdiB3ni8"
      },
      "source": [
        "#Train the Model and save it\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsH15ZSYYQ-G"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "#Testing\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lga3zaOt3rK6"
      },
      "source": [
        "#Test the model on a similar environment and publish the results"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiIxyQvNZGtS"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "#Printing and Visualizing the Results\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu5_cz_ZZNB3"
      },
      "source": [
        "#Print the results\r\n",
        "#Report the observations\r\n",
        "#Create a visualization\r\n",
        "#Write a Conclusion"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}